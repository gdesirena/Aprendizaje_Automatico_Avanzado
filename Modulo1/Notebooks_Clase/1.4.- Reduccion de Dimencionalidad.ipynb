{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# <center> <font color= #000047> Módulo 1: Aprendizaje No supervizado: Reducción de Dimensionalidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorización de Matrices con Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción \n",
    "\n",
    "Cuando trabajamos en problemas de **Machine Learning**, muchas veces nos vamos a encontrar con enormes [conjuntos de datos](https://es.wikipedia.org/wiki/Conjunto_de_datos), con cientos o miles de características o *features*. Una forma simple de reducir las dimensiones de estas características es aplicar alguna técnica de **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)**. La **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)** tiene enormes aplicaciones en todo tipo de problemas relacionados a la [inteligencia artificial](https://es.wikipedia.org/wiki/Inteligencia_artificial), ya que la [reducción de dimensionalidad](https://en.wikipedia.org/wiki/Dimensionality_reduction) es la esencia de la *[cognición](https://es.wikipedia.org/wiki/Cognici%C3%B3n)*. \n",
    "\n",
    "Asimismo, la **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)** es también un tema unificador dentro del álgebra lineal numérica. Una amplia variedad de algoritmos se han desarrollado a lo largo de muchas décadas, proporcionando una plataforma numérica para operaciones de matrices tales como, la resolución de [sistemas de ecuaciones lineales](https://es.wikipedia.org/wiki/Sistema_de_ecuaciones_lineales), la [descomposición espectral](https://es.wikipedia.org/wiki/Teorema_de_descomposici%C3%B3n_espectral), y la identificación de [subespacios vectoriales](https://es.wikipedia.org/wiki/Subespacio_vectorial). \n",
    "\n",
    "Algunos de estos algoritmos también han demostrado ser de utilidad en problemas de análisis estadístico de datos, como es el caso de la [descomposición en valores singulares](https://es.wikipedia.org/wiki/Descomposici%C3%B3n_en_valores_singulares) o [SVD](https://es.wikipedia.org/wiki/Descomposici%C3%B3n_en_valores_singulares), por sus siglas en inglés, que es la base del [análisis de componentes principales](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales) o [PCA](https://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales), que es una técnica muy utilizada para reducir el tamaño de los datos. \n",
    "\n",
    "Muchas investigaciones actuales en **Machine Learning** han centrados sus esfuerzos en el uso de la **Factorización de matrices** para mejorar el rendimiento de los sistemas de aprendizaje. Principalmente en el estudio de la [factorización de matrices no negativas (NMF)](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization), la cual se centra en el análisis de <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matrices de datos</a> cuyos elementos son positivos (no negativos), una ocurrencia muy común en los [conjuntos de datos](https://es.wikipedia.org/wiki/Conjunto_de_datos) derivados de textos e imágenes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ¿Qué es la factorización de matrices?\n",
    "\n",
    "En matemáticas, la factorización es una técnica que consiste en la descomposición de una expresión matemática (que puede ser un número, una <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matriz</a>, un [tensor](https://es.wikipedia.org/wiki/C%C3%A1lculo_tensorial), etc.) en forma de producto. \n",
    "\n",
    "Existen distintos métodos de factorización, dependiendo de los objetos matemáticos estudiados; el objetivo es simplificar una expresión o reescribirla en términos de «bloques fundamentales», que reciben el nombre de *factores*. Así por ejemplo, el número 6 se puede descomponer en el producto de 3 y 2. Si extendemos este concepto al mundo de las <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matrices</a>, entonces podemos decir que la **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)** consiste en encontrar dos o más <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matrices</a> de manera tal que cuando se multipliquen nos devuelvan la <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matriz</a> original. Por ejemplo:\n",
    "\n",
    "$$\\left(\\begin{matrix}3 & 4 & 5\\\\6 & 8 & 10 \\end{matrix}\\right) = \\left(\\begin{matrix}1\\\\2 \\end{matrix}\\right) \\cdot \\left(\\begin{matrix}3 & 4 & 5 \\end{matrix}\\right)\n",
    "$$\n",
    "\n",
    "Los métodos de **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)** han ganado popularidad últimamente al haber sido aplicados con éxito en [sistemas de recomendación](https://es.wikipedia.org/wiki/Sistema_de_recomendaci%C3%B3n) para descubrir las características latentes que subyacen a las interacciones entre dos tipos de entidades, como por ejemplo usuarios y películas. El algoritmo que ganó el [desafío de Netflix](http://netflixprize.com/) fue un sistema basado en métodos de **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Factorización de matrices en sistemas de ecuaciones lineales\n",
    "\n",
    "Dos de las **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)** más utilizadas y que tal vez mucha gente las haya escuchado nombrar alguna vez son:\n",
    "\n",
    "> la [factorización LU](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_LU) \n",
    "\n",
    "> la [factorización QR](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_QR)\n",
    "\n",
    "las cuales se utilizan a menudo para resolver [sistemas de ecuaciones lineales](https://es.wikipedia.org/wiki/Sistema_de_ecuaciones_lineales).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorización LU\n",
    "\n",
    "$$A = LU$$\n",
    "\n",
    "En **álgebra lineal**, la [factorización o descomposición LU](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_LU) (del inglés Lower-Upper) es una forma de [factorización](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n) de una <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matriz</a> como el producto de una [matriz triangular](https://es.wikipedia.org/wiki/Matriz_triangular) inferior y una superior. \n",
    "\n",
    "La **factorización LU** expresa el [método de Gauss](https://es.wikipedia.org/wiki/M%C3%A9todo_de_Gauss) en forma matricial. Así por ejemplo, tenemos que $PA = LU$ donde $P$ es una [matriz de permutación](https://es.wikipedia.org/wiki/Matriz_de_permutaci%C3%B3n). Una condición suficiente para que exista la factorización es que la matriz $A$ sea una [matriz no singular](https://es.wikipedia.org/wiki/Matriz_no_singular).\n",
    "\n",
    "En [Python](https://www.python.org/) podemos encontrar la [descomposición LU](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_LU) con la ayuda de [SciPy](http://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lu_factor.html) de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg as la\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de factorización LU\n",
    "A = np.array([[7,3,-1,2],\n",
    "              [3,8,1,-4],\n",
    "             [-1,1,4,-1],\n",
    "             [2,-4,-1,6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  3, -1,  2],\n",
       "       [ 3,  8,  1, -4],\n",
       "       [-1,  1,  4, -1],\n",
       "       [ 2, -4, -1,  6]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P , L, U = la.lu(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.42857143,  1.        ,  0.        ,  0.        ],\n",
       "       [-0.14285714,  0.21276596,  1.        ,  0.        ],\n",
       "       [ 0.28571429, -0.72340426,  0.08982036,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        ,  3.        , -1.        ,  2.        ],\n",
       "       [ 0.        ,  6.71428571,  1.42857143, -4.85714286],\n",
       "       [ 0.        ,  0.        ,  3.55319149,  0.31914894],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.88622754]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  3., -1.,  2.],\n",
       "       [ 3.,  8.,  1., -4.],\n",
       "       [-1.,  1.,  4., -1.],\n",
       "       [ 2., -4., -1.,  6.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L @ U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorización QR\n",
    "\n",
    "$$A = QR$$\n",
    "\n",
    "La [descomposición o factorización QR](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_QR) consiste en la descomposición de una <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matriz</a> como producto de una [matriz ortogonal](https://es.wikipedia.org/wiki/Matriz_ortogonal) ($Q^T \\cdot Q = I$) por una [matriz triangular superior](https://es.wikipedia.org/wiki/Matriz_triangular). la [factorización QR](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_QR) es ampliamente utilizada en las finanzas cuantitativas como base para la solución del problema de los [mínimos cuadrados lineales](https://es.wikipedia.org/wiki/M%C3%ADnimos_cuadrados_ordinarios), que a su vez se utiliza para el análisis de [regresión estadística](https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal).\n",
    "\n",
    "En [Python](https://www.python.org/) podemos encontrar la [descomposición QR](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_LU) con la ayuda de [SciPy](http://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lu_factor.html) de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = np.array([[12,-51,4],\n",
    "               [6,167,-68],\n",
    "               [-4,24,-41]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12, -51,   4],\n",
       "       [  6, 167, -68],\n",
       "       [ -4,  24, -41]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q,R = la.qr(A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85714286,  0.39428571,  0.33142857],\n",
       "       [-0.42857143, -0.90285714, -0.03428571],\n",
       "       [ 0.28571429, -0.17142857,  0.94285714]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85714286, -0.42857143,  0.28571429],\n",
       "       [ 0.39428571, -0.90285714, -0.17142857],\n",
       "       [ 0.33142857, -0.03428571,  0.94285714]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85714286, -0.42857143,  0.28571429],\n",
       "       [ 0.39428571, -0.90285714, -0.17142857],\n",
       "       [ 0.33142857, -0.03428571,  0.94285714]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.inv(Q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12, -51,   4],\n",
       "       [  6, 167, -68],\n",
       "       [ -4,  24, -41]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12., -51.,   4.],\n",
       "       [  6., 167., -68.],\n",
       "       [ -4.,  24., -41.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q@R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices dispersas y no negativas\n",
    "\n",
    "En muchas ocasiones cuando trabajamos con <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matrices</a> para representar el mundo físico, nos vamos a encontrar con que muchas de estas <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matrices</a> están dominadas por mayoría de elementos que son cero. Este tipo de <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matrices</a> son llamadas [matrices dispersas](https://es.wikipedia.org/wiki/Matriz_dispersa), es decir, <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matrices</a> de gran tamaño en que la mayor parte de sus elementos son cero. Como sería ineficiente almacenar en la memoria de la computadora todos los elementos en cero, en las [matrices dispersas](https://es.wikipedia.org/wiki/Matriz_dispersa) solo vamos a almacenar los valores que no son cero y alguna información adicional acerca de su ubicación.\n",
    "\n",
    "Asimismo muchos datos del mundo real son no negativos y los componentes ocultos correspondientes tienen un sentido físico solamente cuando son no negativos. En la práctica, ambas características, ser dispersas y no negativas son a menudo deseable o necesario cuando los componentes subyacentes tienen una interpretación física. Por ejemplo, en el [procesamiento de imágenes](https://en.wikipedia.org/wiki/Image_processing) y [visión artificial](https://es.wikipedia.org/wiki/Visi%C3%B3n_artificial), las variables involucradas y los parámetros pueden corresponder a píxeles, y la [factorización de matrices dispersas y no negativas](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization) está relacionada con la extracción de las partes más relevantes de las imágenes. La representación *dispersa* de los datos por un número limitado de componentes\n",
    "es un problema importante en la investigación. En [Machine Learning](http://relopezbriega.github.io/tag/machine-learning.html), las [matrices dispersas](https://es.wikipedia.org/wiki/Matriz_dispersa) está estrechamente relacionada con la [selección de atributos](http://relopezbriega.github.io/blog/2016/04/15/ejemplo-de-machine-learning-con-python-seleccion-de-atributos/) y ciertas generalizaciones en algoritmos de aprendizaje; mientras que la *no negatividad* se relaciona a las [distribuciones de probabilidad](http://relopezbriega.github.io/blog/2016/06/29/distribuciones-de-probabilidad-con-python/). \n",
    "\n",
    "En [Python](https://www.python.org/), podemos representar a las [matrices dispersas](https://es.wikipedia.org/wiki/Matriz_dispersa) con la ayuda de [scipy.sparse](http://docs.scipy.org/doc/scipy/reference/sparse.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejemplo de una matriz dispersa\n",
    "A = sp.diags([1,-2,1], [1,0,-1], shape = [10,10], format='csc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  1.,  1., -2.,  1.,  1., -2.,  1.,  1., -2.,  1.,  1., -2.,\n",
       "        1.,  1., -2.,  1.,  1., -2.,  1.,  1., -2.,  1.,  1., -2.,  1.,\n",
       "        1., -2.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1., -2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1., -2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1., -2.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1., -2.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  1., -2.,  1.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  1., -2.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1., -2.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -2.,  1.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -2.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorización de matrices en sistemas de recomendación\n",
    "\n",
    "En un [sistemas de recomendación](https://es.wikipedia.org/wiki/Sistema_de_recomendaci%C3%B3n) como [Netflix](http://www.netflix.com/) o [MovieLens](https://movielens.org/), hay un grupo de usuarios y un conjunto de elementos (películas en los dos sistemas anteriores). Teniendo en cuenta que cada usuario ha valorado algunos elementos en el sistema, nos gustaría predecir cómo los usuarios calificarían los artículos que aún no se han valorado, de tal manera que podemos hacer recomendaciones a los usuarios. En este caso, toda la información que tenemos sobre las calificaciones existentes pueden ser representados en una <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matriz</a>. Supongamos ahora que tenemos 5 usuarios y 4 películas y las calificaciones son números enteros de 1 a 5, la <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matriz</a> resultante puede ser algo como la siguiente (el guión significa que el usuario aún no ha calificado la película):\n",
    "\n",
    "<table>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td></td>\n",
    "<td><strong>P1</strong></td>\n",
    "<td><strong>P2</strong></td>\n",
    "<td><strong>P3</strong></td>\n",
    "<td><strong>P4</strong></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>U1</strong></td>\n",
    "<td>5</td>\n",
    "<td>3</td>\n",
    "<td>-</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>U2</strong></td>\n",
    "<td>4</td>\n",
    "<td>-</td>\n",
    "<td>-</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>U3</strong></td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>-</td>\n",
    "<td>5</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>U4</strong></td>\n",
    "<td>1</td>\n",
    "<td>-</td>\n",
    "<td>-</td>\n",
    "<td>4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>U5</strong></td>\n",
    "<td>-</td>\n",
    "<td>1</td>\n",
    "<td>5</td>\n",
    "<td>4</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Por lo tanto, la tarea de predecir las calificaciones que faltan se puede considerar como un problema de llenar los espacios en blanco (los guiones en la matriz) de tal manera que los valores resultantes serían consistentes con las calificaciones existentes en la <a href=\"https://es.wikipedia.org/wiki/Matriz_(matem%C3%A1ticas)\">matriz</a>.\n",
    "\n",
    "La intuición detrás de usar **[Factorización de matrices](https://es.wikipedia.org/wiki/Factorizaci%C3%B3n_de_matrices)** para resolver este problema es que deberían existir algunas características latentes que determinen cómo un usuario califica una película. Por ejemplo, dos usuarios darían una alta calificación a una cierta película si a ambos les gusta los actores / actrices de la película, o si la película es una película de acción, que es un género preferido por ambos usuarios. Por lo tanto, si podemos descubrir estas características latentes, deberíamos ser capaces de predecir una calificación con respecto a un determinado usuario y una cierta película, porque las características asociadas con el usuario deben coincidir con las características asociadas con la película.\n",
    "\n",
    "Al tratar de descubrir las diferentes características latentes, estamos suponiendo implícitamente que el número de características va a ser menor que el número de usuarios y el número de elementos. No debería ser difícil de entender este supuesto ya que no sería razonable que cada usuario está asociado con una característica única (aunque esto no es imposible). Y de todos modos, si este es el caso, no tendría sentido hacer recomendaciones, porque ninguno de estos usuarios estarían interesados en los artículos calificados por otros usuarios.\n",
    "\n",
    "Si llevamos este ejemplo sencillo a [Python](https://www.python.org/), podríamos modelarlo utilizando [Scikit-learn](http://scikit-learn.org/stable/) [NMF](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) o [Nimfa](http://nimfa.biolab.si/nimfa.methods.factorization.snmf.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
